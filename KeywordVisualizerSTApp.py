import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from wordcloud import WordCloud
import lib.myTextMining as tm
import lib.NaverNewsCrawler as nc
from collections import Counter
from matplotlib import rc, font_manager

# í•œê¸€ í°íŠ¸ ì„¤ì •
font_path = "c:/Windows/Fonts/malgun.ttf"  # ë§‘ì€ ê³ ë”• ê²½ë¡œ
font_name = font_manager.FontProperties(fname=font_path).get_name()
rc('font', family=font_name)

# Streamlit ì„¤ì •
st.set_page_config(layout="wide", page_title="Keyword Visualizer")

# ë„¤ë¹„ê²Œì´ì…˜ ë°” (ì¢Œì¸¡)
st.sidebar.title("ğŸ” ë‰´ìŠ¤ í‚¤ì›Œë“œ ë¶„ì„")
search_query = st.sidebar.text_input("ê²€ìƒ‰ì–´ ì…ë ¥", "")
save_csv = st.sidebar.checkbox("CSV ì €ì¥ ì—¬ë¶€")
uploaded_file = st.sidebar.file_uploader("CSV íŒŒì¼ ì—…ë¡œë“œ", type=["csv"])

# ìŠ¬ë¼ì´ë“œ ë°”: ë‹¨ì–´ ìˆ˜ ì¡°ì ˆ
num_words_freq = st.sidebar.slider("ë¹ˆë„ìˆ˜ ê·¸ë˜í”„ ë‹¨ì–´ ìˆ˜", 5, 50, 20)
num_words_wc = st.sidebar.slider("ì›Œë“œí´ë¼ìš°ë“œ ë‹¨ì–´ ìˆ˜", 10, 100, 50)

# ë°ì´í„° ë¡œë”©
df = None
if uploaded_file:
    df = pd.read_csv(uploaded_file)
    st.sidebar.success("CSV íŒŒì¼ ì—…ë¡œë“œ ì™„ë£Œ")

elif st.sidebar.button("ê²€ìƒ‰ ì‹¤í–‰") and search_query:
    result_all = []
    for start in range(1, 100, 100):  # ë‰´ìŠ¤ 100ê°œ ê°€ì ¸ì˜¤ê¸° (display=100)
        result_json = nc.searchNaverNews(search_query, start=start, display=100)
        if result_json is not None:
            nc.setNewsSearchResult(result_all, result_json)
    df = pd.DataFrame(result_all)
    
    if save_csv:
        filename = f"./data/{search_query}_naver_news.csv"
        nc.saveSearchResult_CSV(result_all, filename)
        st.sidebar.success("CSV ì €ì¥ ì™„ë£Œ")

# í‚¤ì›Œë“œ ë¶„ì„ ë° ì‹œê°í™”
if df is not None and "title" in df.columns:
    st.subheader("í‚¤ì›Œë“œ ì‹œê°í™” ê²°ê³¼")
    
    # ë‰´ìŠ¤ ì œëª© í•©ì¹˜ê¸°
    corpus_list = df["title"].dropna().tolist()
    
    # í˜•íƒœì†Œ ë¶„ì„ ë° ë‹¨ì–´ ì¶”ì¶œ
    from konlpy.tag import Okt
    okt = Okt()
    stopwords = ["ê¸°ì", "ë‰´ìŠ¤", "ì´", "ê·¸", "ì €", "ê²ƒ", "ë“±", "ë”", "í• ", "ìˆ˜", "ë˜", "ì˜", "ì€", "ëŠ”", "ì—", "ì„", "ë¥¼", "ë¡œ", "ê³¼", "ì™€"]
    tags = ['Noun']  # ëª…ì‚¬ë§Œ

    token_list = tm.tokenize_korean_corpus(corpus_list, okt.pos, tags, stopwords)
    counter = Counter(token_list)

    # ë¹ˆë„ìˆ˜ ê·¸ë˜í”„
    top_words_freq = counter.most_common(num_words_freq)
    words_freq, counts_freq = zip(*top_words_freq)

    fig, ax = plt.subplots(figsize=(8, 4))
    sns.barplot(x=list(counts_freq), y=list(words_freq), ax=ax, palette="viridis")
    ax.set_title("í‚¤ì›Œë“œ ë¹ˆë„ìˆ˜")
    ax.set_xlabel("ë¹ˆë„ìˆ˜")
    ax.set_ylabel("ë‹¨ì–´")
    st.pyplot(fig)

    # ì›Œë“œí´ë¼ìš°ë“œ
    top_words_wc = dict(counter.most_common(num_words_wc))
    wordcloud = WordCloud(
        font_path="c:/Windows/fonts/malgun.ttf",
        width=800,
        height=400,
        background_color="white"
    ).generate_from_frequencies(top_words_wc)

    fig_wc, ax_wc = plt.subplots(figsize=(8, 4))
    ax_wc.imshow(wordcloud, interpolation="bilinear")
    ax_wc.axis("off")
    st.pyplot(fig_wc)

else:
    st.warning("ê²€ìƒ‰ì–´ ì…ë ¥ í›„ ê²€ìƒ‰ ì‹¤í–‰ ë˜ëŠ” CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
